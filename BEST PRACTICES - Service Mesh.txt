
Service Mesh

Configurable Infrastructure Layer for Microservices applications. It provides microservices governance by adding necessary visibility and security controls. 

When you have thousands of Discrete services the service mesh helps discover, authorize, track the different service instances. 

One way to implement s service mesh is with sidecars. Sidecars handles intercommmunications with features such as:
* Service Discovery
* Load balancing
* Encryption
* Authentication and Authorization
* Monitoring 
* ....Anything that can be abstracted away from the individual services. This way developer can focus on coding features that add business value rather than infrastrutcure related requirements. 

Istio is a service mesh designed to make communication among microservices reliable, transparent, and secure. Istio intercepts the external and internal traffic targeting the services deployed in container platforms such as Kubernetes.

Though Istio is capable of many things including secure service-to-service communication, automated logging of metrics, enforcing a policy for access controls, rate limits, and quotas, we will focus exclusively on the traffic management features.

Istio lets DevOps teams create rules to intelligently route the traffic to internal services. It is extremely simple to configure service-level properties like circuit breakers, timeouts, and retries, to set up a variety of deployment patterns including blue/green deployments and canary rollouts.

Istio High-Level Flow
	istiod watches Kubernetes APIs and pushes changes to Envoy sidecars in real time
	Kubernetes API Server (watch events) -> istiod (config push) -> Envoy Sidecars (Pods)

Istio CRDs
	Gateway
	VirtualService
	DestinationRule
	PeerAuthentication
	AuthorizationPolicy

istio-ingressgateway 
	Deployment
	Pod (Envoy)
	Service (LoadBalancer)
	Option 1:
		Gateway CRD -> selector: -> istio: ingressgateway # binds to default Istio ingress
		VirtualService CRD -> Gateway CRD
	Option 2:
		patch svc istio-ingressgateway -> "type":"ClusterIP"
		Create Kubernetes Ingress Object with 
			metadata: -> annotations:  kubernetes.io/ingress.class: alb /  alb.ingress.kubernetes.io/scheme: internet-facing
			backend: ->  service: ->  name: istio-ingressgateway
			Browser ->ALB -> Istio Ingress Gateway (Envoy) -> Gateway object (host/port) -> VirtualService (routing rules) -> Backend Pods (mTLS)

Network Traffic Management
	Loadbalancing (Challenge is proliferation of Load balancers)
		DestinationRule -> trafficPolicy: -> loadBalancer: -> simple: RANDOM/ROUND_ROBIN/LEAST_CONN
	Routing (Weight based, Header based, Path based, Mirror Live Traffic)
		Canary(Weight based): 
			Label the pods (app: reviews, version: v1,v2...)
			VirtualService -> route: 
								weight: 10% 
								destination: 
									host: reviews
									subset: v1
			DestinationRule -> (host: reviews) 
								subsets: labels -> version: v1
		Header based:
			HTTP header (enduser: tester) -> VirtualService -> http: 
												- match: 
													- headers: 
														end-user: 
														exact: tester
													route:
													- destination:
														host: reviews
														subset: v1
		Mirror Live Traffic:
			VirtualService -> 
			  http: # L7 load balancing by http path and host, just like K8s ingress resource
					- mirror: # <---- mirror traffic going to v3 to v1 as well, 100% of it
						host: reviews
						subset: v1
					  mirror_percent: 100.0 # use double. https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPRoute
					  route:
						- destination:
							host: reviews
							subset: v3
						weight: 100											
	
Network / Service Resiliency
	Rate Limiting
	Circuit Breaker (To prevent our service going down when they are under high load / cascading failures using Outlier Detection, Self healing, Istio vs Netflix Hystrix Library)
		DestinationRule
		  spec:
			host: backend.default.svc.cluster.local
			trafficPolicy:
				outlierDetection:
				  consecutive5xxErrors: 3
				  interval: 10s
				  baseEjectionTime: 30s
				  maxEjectionPercent: 50
	Fault Tolerance (Retry Policy, 	Timeout)
	Fault Injection (OR) Chaos testing (delay, abort)
		Retry and Fault Injection: VirtualService
				spec:
					hosts: 
					http: 
					- retries:
						attempts: 3 
						perTryTimeout: 3s
						retryOn: 5xx,gateway-error		
					  fault: 
					   delay: # inject latency only for "tester" user
						percentage:
						 value: 100.0 
					   fixedDelay: 15s	

Security
	mTLS
		Enable mTLS Cluster-Wide -> PeerAuthentication CRD (namespace: istio-system, mode: STRICT)
		Enable mTLS Namespace-Wide -> PeerAuthentication CRD (namespace: my-namespace, mode: STRICT)
	Authentication
	Authorization
	Policy

Observability
	Metrics
	Tracing
	Logging

Service Discovery
	Discovery
	Health Check
	
*****************************************************************************************
Deployment Patterns (Dark Launch / Blue Green / Canary / A-B Testing)

Blue / Green Deployment
	Itâ€™s basically a technique for releasing your application in a predictable manner with an goal of reducing any downtime associated with a release.

A/B Testing
	It's a way of testing features in your application for various reasons like usability, popularity, noticeability, etc
	
Canary Deployment
	Canary release is a technique to reduce the risk of introducing a new software version in production by slowly rolling out the change to a small subset of users before rolling it out to the entire infrastructure and making it available to everybody.

*****************************************************************************************

Microservices Capabilities:
	API
	Discovery		-	Kubernetes, Istio
	Invocation		-	Kubernetes
	Elasticity		-	Kubernetes
	Monitoring		-	OpenShift, Istio
	Logging			-	OpenShift
	Pipeline		-	OpenShift
	Resiliency		-	Istio
	Tracing			-	Istio
	Authentication	-	Istio
	

	
Network & Infrastructure can be infiltrated by malicious or misconfigured code 


EKSCtl --> 
Can't use Userdata
Can't Taint Worker nodes
Imperative commands (Create ServiceAccount)



********************************

ArgoCD

Git as the source of truth
Keep your cluster in sync with Git
Easy rollback
Security - Grant access only to ArgoCD
Disaster recovery solution
Cluster / Application state visibility

